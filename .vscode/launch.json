{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python Debugger: Current File",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": false
        },
        {
          "name": "Finetune VLA-Adapter (8x GPU, torchrun)",
          "type": "python",
          "request": "launch",
          "module": "torch.distributed.run",
          "cwd": "${workspaceFolder}/VLA-Adapter",
          "console": "integratedTerminal",
          "justMyCode": false,
          "subProcess": true,
          "env": {
            "data_name": "libero_spatial_no_noops"
          },
          "args": [
            "--standalone",
            "--nnodes", "1",
            "--nproc-per-node", "1",
            "vla-scripts/finetune.py",
            "--vlm_path", "/inspire/ssd/project/robotsimulation/public/data/prism-qwen25-extra-dinosiglip-224px-0_5b",
            "--config_file_path", "pretrained_models/configs",
            // "--data_root_dir", "/inspire/ssd/project/robotsimulation/public/data/OpenVLA/modified_libero_rlds",
            "--data_root_dir", "/inspire/ssd/project/robotsimulation/public/data/modified_libero_rlds",
            "--dataset_name", "libero_spatial_no_noops",
            "--run_root_dir", "outputs",
            "--use_film", "False",
            "--num_images_in_input", "1",
            "--use_proprio", "False",
            "--use_lora", "True",
            "--use_fz", "False",
            "--use_minivlm", "True",
            "--image_aug", "True",
            "--num_steps_before_decay", "400000",
            "--max_steps", "400005",
            "--save_freq", "5000",
            "--save_latest_checkpoint_only", "False",
            "--merge_lora_during_training", "True",
            "--batch_size", "64",
            "--grad_accumulation_steps", "1",
            "--learning_rate", "0.0002",
            "--lora_rank", "64",
            "--use_pro_version", "True",
            "--run_id_note", "VLA-Adapter--libero_spatial_no_noops--${currentDate}-${currentTime}",
            "--use_flow", "True",
          ]
        },
        {
          "name": "Eval LIBERO Spatial (CUDA:0)",
          "type": "python",
          "request": "launch",
          "cwd": "${workspaceFolder}/VLA-Adapter",
          "program": "experiments/robot/libero/run_libero_eval.py",
          "console": "integratedTerminal",
          "justMyCode": true,
          "env": {
            "CUDA_VISIBLE_DEVICES": "0"
          },
          "args": [
            "--use_proprio", "False",
            "--num_images_in_input", "1",
            "--use_film", "False",
            "--pretrained_checkpoint", "/inspire/ssd/project/robotsimulation/public/users/zhangjiahui/vla-rl-dev/VLA-Adapter/outputs/configs+libero_spatial_no_noops+b8+lr-0.0001+lora-r64+dropout-0.0--image_aug--VLA-Adapter--libero_spatial_no_noops----150000_chkpt",
            "--task_suite_name", "libero_spatial",
            "--use_pro_version", "True"
          ]
        },
        {
          "name": "Run Action Generate tutorial",
          "type": "debugpy",
          "request": "launch",
          "cwd": "${workspaceFolder}/world_model/",
          "program": "utils/action_cond_gen_tutorial.py",
          "console": "integratedTerminal",
          "args":[

          ]
        },
        {
          "name": "Debug wm dataset",
          "type": "python",
          "request": "launch",
          "cwd": "${workspaceFolder}/world_model/ActionWorldModel",
          "program": "cosmos_predict2/data/action_conditioned/action_conditioned_libero_dataset.py",
          "console": "integratedTerminal",
          "justMyCode": true,
          "args": [
          ],
          "env": {
              // "CUDA_VISIBLE_DEVICES": "0" 
          }
        },
        {
          "name": "Debug video2world_action",
          "type": "python",
          "request": "launch",
          "cwd": "${workspaceFolder}/world_model/ActionWorldModel",
          "program": "examples/video2world_action.py",
          "console": "integratedTerminal",
          "justMyCode": true,
          "args": [
              "--model_size", "2B",
              // "--dit_path", "/inspire/ssd/project/robotsimulation/public/users/zhangjiahui/vla-rl-dev/world_model/ActionWorldModel/checkpoints/predict2_video2world_2b_action_conditioned_training_2025-09-05_18-26-32/checkpoints/model/iter_000048000.pt",
              // "--input_video", "/inspire/ssd/project/robotsimulation/public/data/AgiBotWorld-Beta-action-processed/clips/529_759750_head_color_clip_00008.mp4",
              // "--input_annotation", "/inspire/ssd/project/robotsimulation/public/data/AgiBotWorld-Beta-action-processed/metadata/529_759750_head_color_clip_00008.npz",
              "--dit_path", "/inspire/ssd/project/robotsimulation/public/users/zhangjiahui/vla-rl-dev/world_model/ActionWorldModel/checkpoints/pretrain/predict2_video2world_2b_action_conditioned_pretraining_2025-09-30_05-39-26/checkpoints/model/iter_000008000.pt",
              
              // "--input_video", "/inspire/ssd/project/robotsimulation/public/users/zhangjiahui/vla-rl-dev/wm_data_process/WM-data-processed/LIBERO-WM/libero_90/clips/agentview_0a4b2744-c0d0-436e-9ebd-1c78280b75be_clip_00002.mp4",
              // "--input_annotation", "/inspire/ssd/project/robotsimulation/public/users/zhangjiahui/vla-rl-dev/wm_data_process/WM-data-processed/LIBERO-WM/libero_90/metadata/agentview_0a4b2744-c0d0-436e-9ebd-1c78280b75be_clip_00002.npz",
              "--input_video", "/inspire/ssd/project/robotsimulation/public/users/zhangjiahui/vla-rl-dev/wm_data_process/WM-data-processed/LIBERO-WM/libero_object/clips/agentview_0a2a5c81-57ef-4891-ae75-94bd59aee817_clip_00002.mp4",
              "--input_annotation", "/inspire/ssd/project/robotsimulation/public/users/zhangjiahui/vla-rl-dev/wm_data_process/WM-data-processed/LIBERO-WM/libero_object/metadata/agentview_0a2a5c81-57ef-4891-ae75-94bd59aee817_clip_00002.npz",
              
              "--num_conditional_frames", "1",
              "--chunk_size", "20",
              "--save_path", "output_debug/generated_video_action.mp4",
              "--guidance", "0",
              "--seed", "0",
              "--disable_guardrail",
              "--disable_prompt_refiner",
              "--autoregressive",
              "--use_black",
              "--use_history",
          ],
          "env": {
              // "CUDA_VISIBLE_DEVICES": "0" 
          }
        },
        {
          "name": "Debug video2world_action pretrain",
          "type": "python",
          "request": "launch",
          "cwd": "${workspaceFolder}/world_model/ActionWorldModel",
          "program": "examples/video2world_action_pretrain.py",
          "console": "integratedTerminal",
          "justMyCode": true,
          "args": [
              "--model_size", "2B",
              // "--dit_path", "/inspire/ssd/project/robotsimulation/public/users/zhangjiahui/vla-rl-dev/world_model/ActionWorldModel/checkpoints/predict2_video2world_2b_action_conditioned_training_2025-09-05_18-26-32/checkpoints/model/iter_000048000.pt",
              // "--input_video", "/inspire/ssd/project/robotsimulation/public/data/AgiBotWorld-Beta-action-processed/clips/529_759750_head_color_clip_00008.mp4",
              // "--input_annotation", "/inspire/ssd/project/robotsimulation/public/data/AgiBotWorld-Beta-action-processed/metadata/529_759750_head_color_clip_00008.npz",
              "--dit_path", "/inspire/ssd/project/robotsimulation/public/users/zhangjiahui/vla-rl-dev/world_model/ActionWorldModel/checkpoints/libero_1008/predict2_video2world_2b_action_conditioned_finetuning_libero_2025-10-07_16-01-00/checkpoints/model/iter_000008000.pt",
              
              // "--input_video", "/inspire/ssd/project/robotsimulation/public/users/zhangjiahui/vla-rl-dev/wm_data_process/WM-data-processed/LIBERO-WM/libero_90/clips/agentview_0a4b2744-c0d0-436e-9ebd-1c78280b75be_clip_00002.mp4",
              // "--input_annotation", "/inspire/ssd/project/robotsimulation/public/users/zhangjiahui/vla-rl-dev/wm_data_process/WM-data-processed/LIBERO-WM/libero_90/metadata/agentview_0a4b2744-c0d0-436e-9ebd-1c78280b75be_clip_00002.npz",
              "--input_video", "/inspire/ssd/project/robotsimulation/public/users/zhangjiahui/vla-rl-dev/wm_data_process/WM-data-processed/LIBERO-WM/libero_object/clips/agentview_0a2a5c81-57ef-4891-ae75-94bd59aee817_clip_00002.mp4",
              "--input_annotation", "/inspire/ssd/project/robotsimulation/public/users/zhangjiahui/vla-rl-dev/wm_data_process/WM-data-processed/LIBERO-WM/libero_object/metadata/agentview_0a2a5c81-57ef-4891-ae75-94bd59aee817_clip_00002.npz",
              
              "--num_conditional_frames", "1",
              "--chunk_size", "20",
              "--save_path", "output_debug/generated_video_action.mp4",
              "--guidance", "0",
              "--seed", "0",
              "--disable_guardrail",
              "--disable_prompt_refiner",
              "--autoregressive",
              "--use_black",
              "--use_history",
          ],
          "env": {
              // "CUDA_VISIBLE_DEVICES": "0" 
          }
        },
        {
          "name": "Regenerate LIBERO",
          "type": "debugpy",
          "request": "launch",
          "cwd": "${workspaceFolder}/any4lerobot/libero2lerobot/",
          "program": "libero_utils/regenerate_libero_dataset.py",
          "console": "integratedTerminal",
          "args":[
            "--libero_task_suite=libero_spatial",
            "--libero_raw_data_dir=/inspire/ssd/project/robotsimulation/public/data/LIBERO-datasets/libero_spatial",
            "--libero_target_dir=debug"
          ],
          "env": {
            // "MUJOCO_GL": "egl",
            // "MUJOCO_GL": "glx",
            "MUJOCO_GL": "osmesa",
            // "LD_PRELOAD": "/usr/lib/x86_64-linux-gnu/libstdc++.so.6"
            
          }
        },
        {
          "name": "Convert LIBERO",
          "type": "debugpy",
          "request": "launch",
          "cwd": "${workspaceFolder}/any4lerobot/libero2lerobot/",
          "program": "libero_h5.py",
          "console": "integratedTerminal",
          "args":[
            "--src-paths=/inspire/ssd/project/robotsimulation/public/data/Debug-dataset/libero_spatial_no_noops",
            "--output-path=/inspire/ssd/project/robotsimulation/public/data/Debug-dataset",
            "--executor=local",
            "--tasks-per-job=1",
            "--workers=1",
            "--debug",
            "--use_delta_action",
          ],
          "env": {
            "MUJOCO_GL": "egl",
            // "MUJOCO_GL": "glx",
            // "MUJOCO_GL": "osmesa",
            // "LD_PRELOAD": "/usr/lib/x86_64-linux-gnu/libstdc++.so.6"
            
          }
        },
        {
          "name": "Debug Process AgiBots 2 Json",
          "type": "debugpy",
          "request": "launch",
          // "cwd": "${workspaceFolder}/any4lerobot/libero2lerobot/",
          "program": "world_model/data_process/agibots_to_json.py",
          "console": "integratedTerminal",
          "args":[
            "--output_dir=/inspire/ssd/project/robotsimulation/public/data/debug",
            "--jobs=1"
          ],
          "env": {
          }
        },
        {
          "name": "Debug Process LIBERO 2 Json",
          "type": "debugpy",
          "request": "launch",
          // "cwd": "${workspaceFolder}/any4lerobot/libero2lerobot/",
          // "program": "world_model/data_process/libero_to_json.py",
          "program": "world_model/data_process/libero_to_json_addi.py",
          "console": "integratedTerminal",
          "args":[
            // "--dataset_dir=/inspire/ssd/project/robotsimulation/public/data/LIBERO-Processed-Additional",
            "--dataset_dir=/inspire/ssd/project/robotsimulation/public/data/LIBERO-Processed-Additional",
            "--libero_task_suite=libero_spatial",
            "--output_dir=/inspire/ssd/project/robotsimulation/public/users/zhangjiahui/vla-rl-dev/work_dirs/debug_data",
            // "--output_dir=/inspire/ssd/project/robotsimulation/public/data/LIBERO-WM/libero_spatial_demo",
            "--debug=False",
            "--jobs=1"
          ],
          "env": {
            // "MUJOCO_GL": "egl",
            // "MUJOCO_GL": "glx",
            "MUJOCO_GL": "osmesa",
            // "LD_PRELOAD": "/usr/lib/x86_64-linux-gnu/libstdc++.so.6"
            
          }
        },
        {
          "name": "Debug Process Openx 2 Json",
          "type": "debugpy",
          "request": "launch",
          "cwd": "${workspaceFolder}/wm_data_process/",
          "program": "utils/openx/openx_to_json.py",
          "console": "integratedTerminal",
          "args":[
            // "--dataset_dir=/inspire/ssd/project/robotsimulation/public/users/zhangjiahui/vla-rl-dev/wm_data_process/data",
            "--output_dir=/inspire/ssd/project/robotsimulation/public/users/zhangjiahui/vla-rl-dev/wm_data_process/data_output_debug",
            "--jobs=1"
          ],
          "env": {
          }
        },
        {
          "name": "Debug Process Droid Raw",
          "type": "debugpy",
          "request": "launch",
          "cwd": "${workspaceFolder}/wm_data_process/utils/droid/python-example-droid-dataset/",
          "program": "src/process_raw_wm_data_multi_process.py",
          "console": "integratedTerminal",
          "args":[
            "--scene", "/inspire/ssd/project/robotsimulation/public/data/droid_raw/1.0.1/TRI",
            "--save_path", "data/droid_processed_data_debug/",
            "--urdf", "franka_description/panda.urdf",
            "--num_threads", "1",
          ],
          "env": {
          }
        },
        {
          "name": "Debug Process Droid Raw 2 Json",
          "type": "debugpy",
          "request": "launch",
          "cwd": "${workspaceFolder}/wm_data_process/",
          "program": "utils/droid/droid_to_json.py",
          "console": "integratedTerminal",
          "args":[
            "--output_dir", "debug",
            "--jobs=1",
          ],
          "env": {
          }
        },
        {
            "name": "Debug Lerobot Train",
            "type": "python",
            "request": "launch",
            "program": "scripts/train.py",
            "cwd": "${workspaceFolder}/lerobot/src/lerobot",
            "args": [
                "--policy.path=/inspire/ssd/project/robotsimulation/public/huggingface_models/smolvla_base",
                // "--dataset.repo_id=/inspire/ssd/project/robotsimulation/public/data/Debug-dataset/libero_spatial_no_noops_lerobot",
                "--dataset.repo_id=/inspire/ssd/project/robotsimulation/public/data/LIBERO-Lerobot/libero_full_lerobot",
                "--batch_size=2",
                "--steps=7000",
                "--output_dir=outputs/train/debug",
                "--job_name=debug",
                "--policy.device=cuda",
                "--policy.push_to_hub=false",
                "--wandb.enable=false"
            ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "0"
            },
            "justMyCode": true,
            "console": "integratedTerminal"
        },
        {
            "name": "Debug Internvl Chat",
            "type": "debugpy",
            "request": "launch",
            "module": "torch.distributed.run",
            "cwd": "${workspaceFolder}/internvl_chat",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
              "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}",
              "TF_CPP_MIN_LOG_LEVEL": "3",
              "LAUNCHER": "pytorch",
              "CUDA_VISIBLE_DEVICES": "0",
            },
            "args": [
              "--nnodes", "1",
              "--node_rank", "0",
              "--master_addr", "127.0.0.1",
              "--nproc_per_node", "1",
              "--master_port", "34339",
              "internvl/train/ft_smolvla.py",
              "--model_name_or_path", "/inspire/ssd/project/robotsimulation/public/huggingface_models/smolvla_base",
              "--conv_style", "smolvla",
              "--output_dir", "work_dirs/debug",
              "--meta_path", "/inspire/ssd/project/robotsimulation/zhangchenxi-253108310322/jasonzhang/vla-rl/internvl_chat/shell/data/debug.json",
              "--overwrite_output_dir", "True",
              "--drop_path_rate", "0.0",
              "--dataloader_num_workers", "1",
              "--bf16", "True",
              "--num_train_epochs", "1",
              "--per_device_train_batch_size", "2",
              "--gradient_accumulation_steps", "1",
              "--save_strategy", "steps",
              "--save_steps", "200",
              "--save_total_limit", "1",
              "--learning_rate", "4e-5",
              "--weight_decay", "0.05",
              "--warmup_ratio", "0.03",
              "--lr_scheduler_type", "cosine",
              "--logging_steps", "1",
              "--do_train", "True",
              "--grad_checkpoint", "True",
              "--group_by_length", "False",
              "--deepspeed", "zero_stage1_config.json",
              "--report_to", "tensorboard"
            ],
          },
          {
            "name": "Debug Internvl Chat 1img",
            "type": "debugpy",
            "request": "launch",
            "module": "torch.distributed.run",
            "cwd": "${workspaceFolder}/internvl_chat",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
              "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}",
              "TF_CPP_MIN_LOG_LEVEL": "3",
              "LAUNCHER": "pytorch",
              "CUDA_VISIBLE_DEVICES": "0",
            },
            "args": [
              "--nnodes", "1",
              "--node_rank", "0",
              "--master_addr", "127.0.0.1",
              "--nproc_per_node", "1",
              "--master_port", "34339",
              "internvl/train/ft_smolvla_1img.py",
              "--model_name_or_path", "/inspire/ssd/project/robotsimulation/public/huggingface_models/smolvla_base",
              "--conv_style", "smolvla",
              "--output_dir", "work_dirs/debug",
              // "--meta_path", "/inspire/ssd/project/robotsimulation/public/users/zhangjiahui/vla-rl-dev/internvl_chat/shell/data/debug.json",
              "--meta_path", "/inspire/ssd/project/robotsimulation/public/users/zhangjiahui/vla-rl-dev/internvl_chat/shell/data/libero/libero_spatial.json",
              "--overwrite_output_dir", "True",
              "--drop_path_rate", "0.0",
              "--dataloader_num_workers", "1",
              "--bf16", "True",
              "--num_train_epochs", "1",
              "--per_device_train_batch_size", "2",
              "--gradient_accumulation_steps", "1",
              "--save_strategy", "steps",
              "--save_steps", "200",
              "--save_total_limit", "1",
              "--learning_rate", "4e-5",
              "--weight_decay", "0.05",
              "--warmup_ratio", "0.03",
              "--lr_scheduler_type", "cosine",
              "--logging_steps", "1",
              "--do_train", "True",
              "--grad_checkpoint", "True",
              "--group_by_length", "False",
              "--deepspeed", "zero_stage1_config.json",
              "--report_to", "tensorboard"
            ],
          },
          {
            "name": "Debug Internvl Chat UR",
            "type": "debugpy",
            "request": "launch",
            "module": "torch.distributed.run",
            "cwd": "${workspaceFolder}/internvl_chat",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
              "PYTHONPATH": "${env:PYTHONPATH}:${workspaceFolder}",
              "TF_CPP_MIN_LOG_LEVEL": "3",
              "LAUNCHER": "pytorch",
              "CUDA_VISIBLE_DEVICES": "0",
            },
            "args": [
              "--nnodes", "1",
              "--node_rank", "0",
              "--master_addr", "127.0.0.1",
              "--nproc_per_node", "1",
              "--master_port", "34339",
              "internvl/train/ft_smolvla_ur_real.py",
              "--model_name_or_path", "/SSD_DISK/users/zhangjiahui/SimpleVLA-RL/hugg_models/smolvla_base",
              "--conv_style", "smolvla",
              "--output_dir", "work_dirs/debug",
              "--meta_path", "/SSD_DISK/users/zhangjiahui/SimpleVLA-RL/internvl_chat/shell/data/ur_real_jsonl.json",
              "--overwrite_output_dir", "True",
              "--drop_path_rate", "0.0",
              "--dataloader_num_workers", "1",
              "--bf16", "True",
              "--num_train_epochs", "1",
              "--per_device_train_batch_size", "2",
              "--gradient_accumulation_steps", "1",
              "--save_strategy", "steps",
              "--save_steps", "200",
              "--save_total_limit", "1",
              "--learning_rate", "4e-5",
              "--weight_decay", "0.05",
              "--warmup_ratio", "0.03",
              "--lr_scheduler_type", "cosine",
              "--logging_steps", "1",
              "--do_train", "True",
              "--grad_checkpoint", "True",
              "--group_by_length", "False",
              "--deepspeed", "zero_stage1_config.json",
              "--report_to", "tensorboard"
            ],
          },
          {
            "name": "torchrun: val cosmos_predict2",
            "type": "python",
            "request": "launch",
            "module": "torch.distributed.run",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--nproc_per_node=2",
                "--master_port=12341",
                "-m",
                "scripts.train",
                "--config=cosmos_predict2/configs/base/config_agibot_val.py",
                "--experiment=predict2_video2world_2b_action_conditioned_evaling"
            ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "6,7"
            }
          },
          {
            "name": "Debug sft qwenvl",
            "type": "python",
            "request": "launch",
            "module": "torch.distributed.run",
            "cwd": "${workspaceFolder}/qwenvl_chat",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--nnodes=1",
                "--node_rank=0",
                "--master_addr=127.0.0.1",
                "--nproc_per_node=1",
                "--master_port=32002",
                "src/train/train_sft.py",
                "--use_liger", "False",
                "--lora_enable", "True",
                "--use_dora", "False",
                "--lora_namespan_exclude", "['lm_head', 'embed_tokens']",
                "--lora_rank", "64",
                "--lora_alpha", "64",
                "--lora_dropout", "0.05",
                "--num_lora_modules", "-1",
                "--deepspeed", "scripts/zero_stage1_config.json",
                "--model_id", "/inspire/ssd/project/robotsimulation/public/huggingface_models/Qwen2.5-VL-7B-Instruct",
                "--data_path", "shell/data/train_rm_500.json",
                "--remove_unused_columns", "False",
                "--freeze_vision_tower", "True",
                "--freeze_llm", "True",
                "--freeze_merger", "False",
                "--bf16", "True",
                "--fp16", "False",
                "--disable_flash_attn2", "False",
                "--output_dir", "work_dirs/qwen2.5-vl-sft-lora-baseline",
                "--num_train_epochs", "1",
                "--per_device_train_batch_size", "2",
                "--gradient_accumulation_steps", "1",
                "--image_min_pixels", "100352", // 计算后的值 (112 * 28 * 28)
                "--image_max_pixels", "100352", // 计算后的值 (112 * 28 * 28)
                "--learning_rate", "1e-4",
                "--weight_decay", "0.1",
                "--warmup_ratio", "0.03",
                "--lr_scheduler_type", "cosine",
                "--logging_steps", "1",
                "--tf32", "True",
                "--gradient_checkpointing", "True",
                "--report_to", "tensorboard",
                "--lazy_preprocess", "True",
                "--save_strategy", "steps",
                "--save_steps", "200",
                "--save_total_limit", "10",
                "--dataloader_num_workers", "4"
            ]
          },
          {
            "name": "Debug qwenvl rm eval",
            "type": "debugpy",
            "request": "launch",
            "cwd": "${workspaceFolder}/qwenvl_chat/",
            "program": "utils/eval_reward_model.py",
            "console": "integratedTerminal",
            "args":[
              // "--debug"
            ]
          },
          {
            "name": "Debug VLAC QuickStart",
            "type": "python",
            "request": "launch",
            "cwd": "${workspaceFolder}/VLAC",
            "program": "quick_start.py",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
            ],
            "env": {
                // "CUDA_VISIBLE_DEVICES": "0" 
            }
          },
          {
            "name": "Debug VLAC eval",
            "type": "python",
            "request": "launch",
            "cwd": "${workspaceFolder}/VLAC",
            "program": "eval_reward_model.py",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
              // "--debug"
            ],
            "env": {
                // "CUDA_VISIBLE_DEVICES": "0" 
            }
          },
    ]
}